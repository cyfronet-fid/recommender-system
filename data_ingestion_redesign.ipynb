{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FLASK_ENV=development\n"
     ]
    }
   ],
   "source": [
    "%env FLASK_ENV=development"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 18:07:49.944642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-18 18:07:49.944664: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-18 18:07:49.944939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from mongoengine import connect, disconnect\n",
    "\n",
    "from settings import DevelopmentConfig\n",
    "\n",
    "from recommender.models import Service, User\n",
    "from recommender.engines.nlp_embedders.embedders import Services2tensorsEmbedder, Users2tensorsEmbedder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<recommender.engines.nlp_embedders.embedders.Users2tensorsEmbedder at 0x7fe8342c4d90>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Services2tensorsEmbedder()\n",
    "Users2tensorsEmbedder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "disconnect()\n",
    "connection = connect(host=DevelopmentConfig.MONGODB_HOST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Object to Vector Concept\n",
    "\n",
    "object -> vec\n",
    "\n",
    "object has known structure so it's easier than variable structure. We can do one net architecture for given structure :)\n",
    "\n",
    "Input data models is:\n",
    "List of dicts of lists of dicts of strings (there is no error in this phrase XD)\n",
    "\n",
    "### Example of data\n",
    "```\n",
    "batch = [\n",
    "    object1 = {\n",
    "        \"field1\": [\n",
    "            {\n",
    "                \"sub_field1_1\": \"val1\",\n",
    "                \"sub_field1_2\": \"val2\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field1_1\": \"val3\",\n",
    "                \"sub_field1_2\": \"val4\"\n",
    "            }\n",
    "        ],\n",
    "        \"field2\": [\n",
    "            {\n",
    "                \"sub_field2_1\": \"val5\",\n",
    "                \"sub_field2_2\": \"val6\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field2_1\": \"val7\",\n",
    "                \"sub_field2_2\": \"val8\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    object2 = {\n",
    "        \"field1\": [\n",
    "            {\n",
    "                \"sub_field1_1\": \"val9\",\n",
    "                \"sub_field1_2\": \"val10\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field1_1\": \"val11\",\n",
    "                \"sub_field1_2\": \"val12\"\n",
    "            }\n",
    "        ],\n",
    "        \"field2\": [\n",
    "            {\n",
    "                \"sub_field2_1\": \"val13\",\n",
    "                \"sub_field2_2\": \"val14\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field2_1\": \"val15\",\n",
    "                \"sub_field2_2\": \"val16\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "```\n",
    "### Next step\n",
    "\n",
    "```\n",
    "batch = [\n",
    "    object1 = {\n",
    "        \"sub_field1_1\": [\"val1\", \"val3\"],\n",
    "        \"sub_field1_2\": [\"val2\", \"val4\"],\n",
    "        \"sub_field2_1\": [\"val5\", \"val7\"],\n",
    "        \"sub_field2_2\": [\"val6\", \"val8\"],\n",
    "    },\n",
    "    object2 = {\n",
    "        \"sub_field1_1\": [\"val9\", \"val11\"],\n",
    "        \"sub_field1_2\": [\"val10\", \"val12\"],\n",
    "        \"sub_field2_1\": [\"val13\", \"val15\"],\n",
    "        \"sub_field2_2\": [\"val14\", \"val16\"],\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "### Next step\n",
    "\n",
    "```\n",
    "batch_sub_field1_1 = [\n",
    "    [\"val1\", \"val3\"],\n",
    "    [\"val9\", \"val11\"]\n",
    "]\n",
    "\n",
    "batch_sub_field1_2 = [\n",
    "    [\"val2\", \"val4\"],\n",
    "    [\"val10\", \"val12\"]\n",
    "]\n",
    "\n",
    "batch_sub_field2_1 = [\n",
    "    [\"val5\", \"val7\"],\n",
    "    [\"val13\", \"val15\"]\n",
    "]\n",
    "\n",
    "batch_sub_field2_2 = [\n",
    "    [\"val6\", \"val8\"],\n",
    "    [\"val14\", \"val16\"]\n",
    "]\n",
    "```\n",
    "\n",
    "### Next step (target form)\n",
    "\n",
    "```\n",
    "batch_sub_field1_1 = [\n",
    "    [vec1, vec3],\n",
    "    [vec9, vec11]\n",
    "]\n",
    "\n",
    "batch_sub_field1_2 = [\n",
    "    [vec2, vec4],\n",
    "    [vec10, vec12]\n",
    "]\n",
    "\n",
    "batch_sub_field2_1 = [\n",
    "    [vec5, vec7],\n",
    "    [vec13, vec15]\n",
    "]\n",
    "\n",
    "batch_sub_field2_2 = [\n",
    "    [vec6, vec8],\n",
    "    [vec14, vec15]\n",
    "]\n",
    "```\n",
    "\n",
    "objects can be nested (in the limited way) so we have to have ways of embedding:\n",
    "- basic types: strings encoded with text2vec (done with [Universal Sentence Encoder](https://github.com/MartinoMensio/spacy-universal-sentence-encoder))\n",
    "- lists: Lists need flattening of the temporal dimension (using e.g.: mean() ) - done using so called handlers\n",
    "- dicts: no problemo, we split them into separate batches - done using so called handlers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Theoretical time complexity is linear :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execution time tests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[<Service: Service object>]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Service.objects[:1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 s ± 24.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Services2tensorsEmbedder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "services2tensors_embedder = Services2tensorsEmbedder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 ms ± 500 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit services2tensors_embedder(Service.objects[:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "x, d = services2tensors_embedder(Service.objects[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import spacy_universal_sentence_encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "nlp = spacy_universal_sentence_encoder.load_model(\"en_use_lg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "I have"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"I have\").doc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 s ± 222 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit services2tensors_embedder(Service.objects[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 ms ± 10 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Users2tensorsEmbedder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "users2tensors_embedder = Users2tensorsEmbedder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 1024])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, d = users2tensors_embedder(User.objects[:10])\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.3 ms ± 1.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users2tensors_embedder(User.objects[:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 ms ± 21.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users2tensors_embedder(User.objects[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "with open(\"./xd\", \"wb\") as file:\n",
    "    pickle.dump([1,2,3], file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./xd\", \"rb\") as file:\n",
    "    xd = pickle.load(file)\n",
    "    print(xd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "Now we can embedd Users, Services or almost any other objects without any embedders training and whole dataset collection in real time. We can do it to new objects that we've never seen before. We are not constrained by possible values of object fields or by old DB dumps or by existing or not existing IDs. Data can be in the any language!!!\n",
    "\n",
    "It's a little bit too good to be true, so extensive tests of recommendation power needed.\n",
    "\n",
    "NLP part could and should be vastly extended and improved, for now there is necessary minimum and no more.\n",
    "\n",
    "Some mechanism for dimensinality reduction should be proposed, e.g.:\n",
    "- polling in the first layers of networks that deal with user/services\n",
    "- NLP-based sentences concatenation\n",
    "\n",
    "If above ideas works (tests needed) the big part of the recommender system that deals with data preparation could be removed.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Is it possible to ingest MP DB changes as events in the Recommender and use them for online training and how exactly should it be done?\n",
    "> -- <cite>[Data Ingestion Redesign Issue #348](https://github.com/cyfronet-fid/recommender-system/issues/348)</cite>\n",
    "\n",
    "> ### Yes, it's possible and can be done using already implemented technique presented above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What the excellent PR should have:\n",
    "- implementation\n",
    "- tests\n",
    "- refactoring done\n",
    "- docstrings, examples, readme\n",
    "- typing\n",
    "- black, pylint run\n",
    "- theoretical time and memory complexity\n",
    "- practical time and memory complexity: profiling\n",
    "- usage of multiprocesing\n",
    "- usage of loggers, verbosity\n",
    "- progress bars if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}