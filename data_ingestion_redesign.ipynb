{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FLASK_ENV=development\n"
     ]
    }
   ],
   "source": [
    "%env FLASK_ENV=development"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.local/share/virtualenvs/recommender-system-r71yvAN0/lib/python3.7/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2022-04-28 09:02:19.188598: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-04-28 09:02:19.188695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-Jan\n",
      "2022-04-28 09:02:19.188723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-Jan\n",
      "2022-04-28 09:02:19.188919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.103.1\n",
      "2022-04-28 09:02:19.188981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.103.1\n",
      "2022-04-28 09:02:19.188997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.103.1\n",
      "2022-04-28 09:02:19.189540: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from mongoengine import connect, disconnect\n",
    "\n",
    "from settings import DevelopmentConfig\n",
    "\n",
    "from recommender import User\n",
    "from recommender.models import Service\n",
    "from recommender.engines.nlp_embedders.embedders import services2tensor, users2tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "disconnect()\n",
    "connection = connect(host=DevelopmentConfig.MONGODB_HOST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Object to Vector Concept\n",
    "\n",
    "object -> vec\n",
    "\n",
    "object has known structure so it's easier than variable structure. We can do one net architecture for given structure :)\n",
    "\n",
    "Input data models is:\n",
    "List of dicts of lists of dicts of strings (there is no error in this phrase XD)\n",
    "\n",
    "### Example of data\n",
    "```\n",
    "batch = [\n",
    "    object1 = {\n",
    "        \"field1\": [\n",
    "            {\n",
    "                \"sub_field1_1\": \"val1\",\n",
    "                \"sub_field1_2\": \"val2\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field1_1\": \"val3\",\n",
    "                \"sub_field1_2\": \"val4\"\n",
    "            }\n",
    "        ],\n",
    "        \"field2\": [\n",
    "            {\n",
    "                \"sub_field2_1\": \"val5\",\n",
    "                \"sub_field2_2\": \"val6\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field2_1\": \"val7\",\n",
    "                \"sub_field2_2\": \"val8\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    object2 = {\n",
    "        \"field1\": [\n",
    "            {\n",
    "                \"sub_field1_1\": \"val9\",\n",
    "                \"sub_field1_2\": \"val10\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field1_1\": \"val11\",\n",
    "                \"sub_field1_2\": \"val12\"\n",
    "            }\n",
    "        ],\n",
    "        \"field2\": [\n",
    "            {\n",
    "                \"sub_field2_1\": \"val13\",\n",
    "                \"sub_field2_2\": \"val14\"\n",
    "            },\n",
    "            {\n",
    "                \"sub_field2_1\": \"val15\",\n",
    "                \"sub_field2_2\": \"val16\"\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "```\n",
    "### Next step\n",
    "\n",
    "```\n",
    "batch = [\n",
    "    object1 = {\n",
    "        \"sub_field1_1\": [\"val1\", \"val3\"],\n",
    "        \"sub_field1_2\": [\"val2\", \"val4\"],\n",
    "        \"sub_field2_1\": [\"val5\", \"val7\"],\n",
    "        \"sub_field2_2\": [\"val6\", \"val8\"],\n",
    "    },\n",
    "    object2 = {\n",
    "        \"sub_field1_1\": [\"val9\", \"val11\"],\n",
    "        \"sub_field1_2\": [\"val10\", \"val12\"],\n",
    "        \"sub_field2_1\": [\"val13\", \"val15\"],\n",
    "        \"sub_field2_2\": [\"val14\", \"val16\"],\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "### Next step\n",
    "\n",
    "```\n",
    "batch_sub_field1_1 = [\n",
    "    [\"val1\", \"val3\"],\n",
    "    [\"val9\", \"val11\"]\n",
    "]\n",
    "\n",
    "batch_sub_field1_2 = [\n",
    "    [\"val2\", \"val4\"],\n",
    "    [\"val10\", \"val12\"]\n",
    "]\n",
    "\n",
    "batch_sub_field2_1 = [\n",
    "    [\"val5\", \"val7\"],\n",
    "    [\"val13\", \"val15\"]\n",
    "]\n",
    "\n",
    "batch_sub_field2_2 = [\n",
    "    [\"val6\", \"val8\"],\n",
    "    [\"val14\", \"val16\"]\n",
    "]\n",
    "```\n",
    "\n",
    "### Next step (target form)\n",
    "\n",
    "```\n",
    "batch_sub_field1_1 = [\n",
    "    [vec1, vec3],\n",
    "    [vec9, vec11]\n",
    "]\n",
    "\n",
    "batch_sub_field1_2 = [\n",
    "    [vec2, vec4],\n",
    "    [vec10, vec12]\n",
    "]\n",
    "\n",
    "batch_sub_field2_1 = [\n",
    "    [vec5, vec7],\n",
    "    [vec13, vec15]\n",
    "]\n",
    "\n",
    "batch_sub_field2_2 = [\n",
    "    [vec6, vec8],\n",
    "    [vec14, vec15]\n",
    "]\n",
    "```\n",
    "\n",
    "objects can be nested (in the limited way) so we have to have ways of embedding:\n",
    "- basic types: strings encoded with text2vec (done with [Universal Sentence Encoder](https://github.com/MartinoMensio/spacy-universal-sentence-encoder))\n",
    "- lists: Lists need flattening of the temporal dimension (using e.g.: mean() ) - done using so called handlers\n",
    "- dicts: no problemo, we split them into separate batches - done using so called handlers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Theoretical time complexity is linear :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execution time tests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.3 ms ± 3.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit services2tensor(Service.objects[:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1 s ± 159 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit services2tensor(Service.objects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "services = services2tensor(Service.objects[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 9728])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.62 ms ± 33.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users2tensor(User.objects[:1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81 s ± 39.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users2tensor(User.objects)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "Now we can embedd Users, Services or almost any other objects without any embedders training and whole dataset collection in real time. We can do it to new objects that we've never seen before. We are not constrained by possible values of object fields or by old DB dumps or by existing or not existing IDs. Data can be in the any language!!!\n",
    "\n",
    "It's a little bit too good to be true, so extensive tests of recommendation power needed.\n",
    "\n",
    "NLP part could and should be vastly extended and improved, for now there is necessary minimum and no more.\n",
    "\n",
    "Some mechanism for dimensinality reduction should be proposed, e.g.:\n",
    "- polling in the first layers of networks that deal with user/services\n",
    "- NLP-based sentences concatenation\n",
    "\n",
    "If above ideas works (tests needed) the big part of the recommender system that deals with data preparation could be removed.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Is it possible to ingest MP DB changes as events in the Recommender and use them for online training and how exactly should it be done?\n",
    "> -- <cite>[Data Ingestion Redesign Issue #348](https://github.com/cyfronet-fid/recommender-system/issues/348)</cite>\n",
    "\n",
    "> ### Yes, it's possible and can be done using already implemented technique presented above"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What the excellent PR should have:\n",
    "- implementation\n",
    "- tests\n",
    "- refactoring done\n",
    "- docstrings, examples, readme\n",
    "- typing\n",
    "- black, pylint run\n",
    "- theoretical time and memory complexity\n",
    "- practical time and memory complexity: profiling\n",
    "- usage of multiprocesing\n",
    "- usage of loggers, verbosity\n",
    "- progress bars if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}