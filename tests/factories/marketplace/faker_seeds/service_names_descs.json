{
    "AMBER": "Simple and user-friendly NMR-based refinement of the 3D structures of biological macromolecules\nthought the AMPS-NMR portal. Amber (Assisted Model Building with Energy Refinement) is a suite\nof programs that allow users to perform molecular dynamics (MD) simulations on biological systems\nand to store different calculations.\n\nThe portal was developed with the help of the WestLife and INDIGO-DataCloud projects\nand supported by the MoBrain Competence Centre, under the EGI-Engage project.\n",
    "Alien and Invasive Species Virtual Research Environment": "Alien and Invasive Species Virtual Research Environment (VRE) is a web-based, comprehensive,\ncollaborative working environment supporting decision makers and scientists in predicting the spread\nof an invasive species (possibly alien) in a new environment. The VRE hosts examples of suitable habitat maps\nproduced for today and 2050 in new areas for more than 11,000 species and provides models and workflows\nto combine environmental data with species observations in their habitats to predict their future spread.\n\n### Features:\n  - A service providing state-of-the art Data Analytics algorithms suitable for alien\n    and invasive species spread prediction;\n  - A service for seamless discovery and access to species occurrence data and taxa names\n    from several providers providers (eg. BrazilianFlora, OBIS, WoRMS, GBIF, ITIS, CatalogueOfLife);\n  - A complete spatial data infrastructure for discovering, accessing and publishing\n    spatial datasets according to OGC standards;\n  - A catalogue service for discovering, accessing and publishing any research object\n    (multi-part objects with actionable parts) and promoting its re-use;\n  - A social networking service supporting communication among VRE members by sharing and commenting posts;\n",
    "B2ACCESS": "The B2ACCESS AAI proxy service is arbitrating access to registered Service Providers via different protocols.\nIntegrated Service Providers consume Attribute assertions from the B2ACCESS service when the End User\naccesses them. B2ACCESS allows EUDAT users to authenticate themselves using a variety of other Identity\nProviders or credentials.\n\n### The features of B2ACCESS:\n\n  - supports several methods of authentication via the users' primary identity providers (OpenID, SAML, x.509)\n  - can be used as primary identity provider, if necessary\n  - can be integrated with any service of the CDI service provider federation\n  - is integrated with EduGain and supports identities from theoretically hundreds of Universities\n    and Research institutions worldwide.\n  - provides unique and persistent EUDAT-wide meaningful identifiers.\n",
    "B2DROP": "B2DROP is a secure and trusted data exchange service for researchers and scientists to keep their research data synchronized and up-to-date and to exchange with other researchers. B2DROP is an ideal solution to store and exchange data with colleagues and team members, synchronise multiple versions of data, ensure automatic desktop synchronisation of large files.\n\nFor the individuals researchers who need to synchronise and exchange data with one or multiple users, B2DROP Service is a customer-facing solution to store and exchange data with colleagues and team members.\n\n### Uses cases:\n\n  - define with whom to exchange data, for how long and how\n  - are offered up to 20GB of storage space for research data\n  - access and manage permissions to files from any device and any location\n\n### To access the service you need to:\n\n1.  The EUDAT public B2DROP service (https://b2drop.eudat.eu) is offered as a fairshare free-to-use service, users can register themselves via the B2DROP service. Users get a default quota of 20GB.\n2.  Requests for higher quotas or a dedicated instance can by selecting one of the service options below.\n3.  Set the relevant parameters and add the service to the cart.\n4.  Go to the cart and submit your order.\n5.  You will receive an email summarising your order.\n6.  You will be contacted by the EUDAT support team.\n\n### Service provided by\n\nEUDAT and JSC.\n",
    "B2FIND": "B2FIND is the EUDAT metadata service and provides a discovery portal which allows users\nto find data collections within an international and inter-disciplinary scope.\nIt is based on a comprehensive metadata catalogue of research data collections stored\nin EUDAT data centres and other repositories. Harmonization of the metadata descriptions collected\nfrom heterogeneous sources enables not only the presentation in a consistent form but as well\nthe faceted search across scientific domain boundaries.\n\nB2FIND is for communities and other providers of research data who need to publish and give visibility\nto their metadata and individual researchers who need to search data from everywhere,\nand see data in the context with an accross community approach.\n\n### Features:\n\n   - based on a comprehensive joint catalogue of EUDAT services and external metadata\n   - metadata is mapped onto standardized facets\n   - supports faceted, geospatial and temporal metadata searches\n   - allows users to search and browse datasets via keyword searches\n   - results displayed in user-friendly format and listed in order of relevance\n   - access to the scientific data objects is given through references provided in the metadata\n   - available for communities in the EUDAT registered domain of data\n\n### Uses cases:\n\n   - define with whom to exchange data, for how long and how\n   - are offered up to 20GB of storage space for research data\n   - access and manage permissions to files from any device and any location\n\n\n### To access the service you need to:\n\n   1. The EUDAT public B2FIND [service][1]  is offered as a fairshare free-to-use service,\n   no registration is required to search through the B2FIND service.\n   2. Request for metadata data harvesting of an existing data repository select the service option below.\n   3. Provide URL to data repository\n   4. Provide URL endpoint for harvesting, see B2FIND [guidelines][2] for harvesting\n   5. Go to the cart and submit your order.\n   6. You will receive an email summarising your order.\n   7. You will be contacted by the EUDAT support team\n\n### Service provided by\n\nEUDAT and Deutsches Klimarechenzentrum (DKRZ)\n\n[1]: https://b2find.eudat.eu/\n[2]: http://b2find.eudat.eu/guidelines/harvesting.html\n",
    "B2HANDLE": "B2HANDLE is the distributed service for minting, storing, managing and accessing persistent identifiers (PIDs) and essential metadata (PID records) as well as managing PID namespaces. The implementation of the service relies on the DONA/Handle persistent identifier solution.\n\nB2HANDLE can be used by middleware applications, end-user tools and other service to reliably identify data objects over longer timespans and through changes in object location or ownership. The B2HANDLE service encompasses management of identifier namespaces (Handle prefixes), establishment of policies and business workflows, operation of Handle servers and technical services, and a user-friendly Python library for general interaction with Handle servers and EUDAT-specific extensions. B2HANDLE is mostly transparents to end-users, shielding them from the complexity of infrastructure details. In the background, B2HANDLE operates as a federation and based on policies that aim to ensure high availability of Handle resolution by cross-site mirroring of Handles. B2HANDLE supports a dedicated Handle record structure (a PID profile) for the safe data management within an infrastructure with a given topology. By relying on features of the PID profile, end-users can, for instance, ensure authenticity of objects with checksums and timestamps and account for replicated objects across multiple locations.\n\n### Note:\n\nTo mint PIDs a prefix is required.\n\n\n### To access the service you need to:\n\n   1. Requests access to PID service or namespace (Prefix) select one of service options below.\n   2. Set the relevant parameters and add the service to the cart.\n   3. Go to the cart and submit your order.\n   4. You will receive an email summarising your order.\n   5. You will be contacted by the EUDAT support team.\n\n### Service provided by\n\nEUDAT and SURFsara, GRNET\n",
    "B2NOTE": "B2Note allows to easily create, search and manage annotations. An annotation is a keyword or commentary attached to a dete object (data collection, file) that explains or classifies it. B2NOTE is a standalone service for annotating data content hosted within the EUDAT CDI.\n\nThere exist 3 types of annotations in B2Note\n\n   - the semantic tag, a keyword from an ontology (a semantic tag coming from identified ontology repositories - currently only Bioportal\n   - the free-text keyword, to be created and used when a specific semantic term is not found\n   - the comment, a more comprehensive annotation\n\nPerfect for service providers who want to extend the (web based) service with annotation functionality\n\n### Relevant:\n\nUser must register to create and maintain annotations, additional access registration can be applied on the service which enabled annotation functionality via B2NOTE. Service providers willing to enable annotation via B2NOTE on an existing service can request consultancy and support.\n\n### To access the service you need to:\n\n   1. The EUDAT public B2NOTE service (https://b2note.eudat.eu) is offered as a fairshare free-to-use service, no registration is required to search through the B2NOTE, registration is needed to store and manage annotations.\n   2. Request for integraton within existing services select the service option below.\n   3. Provide URL to service\n   4. Go to the cart and submit your order.\n   5. You will receive an email summarising your order.\n   6. You will be contacted by the EUDAT support team\n\n### Service provided by\n\nEUDAT and BSC\n",
    "B2SAFE": "B2SAFE is a robust, safe and highly available service which allows community\nand departmental repositories to implement data management policies on their research data across\nmultiple administrative domains in a trustworthy manner. The service provides an abstraction layer\nof large scale, heterogeneous data storages and guards against data loss in long-term archiving.\nIt allows to optimize access for users (e.g. from different regions) and brings data closer to facilities\nfor compute-intensive analysis.\n\n\n### To access the service you need to:\n\n   1. Request access selecting one of the service options below.\n   2. Set the relevant parameters and add the service to the cart.\n   3. Go to the cart and submit your order.\n   4. You will receive an email summarising your order..\n   5. You will be contacted by the EUDAT support team.\n\n### Service provided by\n\nEUDAT and all generic CDI Level 1 providers\n",
    "B2SHARE": "B2SHARE is a user-friendly, reliable and trustworthy way for researchers,\nscientific communities and citizen scientists to store and publish small-scale\nresearch data from diverse contexts. B2SHARE is a solution that facilitates research data storage,\nguarantees long-term persistence of data and allows data, results or ideas to be shared worldwide.\n\n   - The basic production service comprises the following features:\n   - self-service registration for any scientists and researchers,\n   - free upload and registration of stable research data,\n   - data access policy is defined by the data owner,\n   - metadata is openly accessible and harvestable,\n   - customised metadata handling and customized user interfaces (e.g. for metadata acquisition),\n   - data integrity is ensured by checksums which are calculated during data ingest,\n   - the data is kept online, the storage usage base on the principle of fair share.\n\nPerfect for the individuals researchers who do not have adequate facilities for storing,\npreserving and sharing data, B2SHARE Service is a customer-facing service which provides\na safe repository for scientific data and a easy way to share it in the research community.\n\n\n### To access the service you need to:\n\n   1. The EUDAT public B2SHARE service (https://b2share.eudat.eu) is offered as a fairshare free-to-use service, users can register themselves via the B2SHARE service.\n   2. Requests for a specific community domain and metadata template or a dedicated instance can by selecting one of the service options below.\n   3. Set the relevant parameters and add the service to the cart.\n   4. Go to the cart and submit your order.\n   5. You will receive an email summarising your order.\n   6. You will be contacted by the EUDAT support team.\n\n### Service provided by\n\nEUDAT and CSC\n",
    "B2STAGE": "B2STAGE is for communities who need to transfert large data collection from EUDAT CDI to HPC.\nB2STAGE service is a customer-facing service that allow high performance transfers\nin a reliable, fast, easy to use environment.\n\nThe service allows users to:\n\n   - transfer large data collections from EUDAT storage facilities to external HPC facilities for processing\n   - ingest computation results onto the EUDAT infrastructure\n   - access stored data sets through associated PIDs\n   - in conjunction with B2SAFE, replicate community data sets, ingesting them onto\n   EUDAT storage resources for long-term preservation.\n\n### Service provided by\n\nEUDAT and all generic EUDAT CDI Level 1 providers.\n",
    "CS-ROSETTA": "The CS-ROSETTA3 web portal allows structural biologists to model the 3D structure of proteins\nusing only the 13CA, 13CB, 13C\u2019, 15N, 1HA and 1HN NMR chemical shifts as input.\n",
    "CSC ePouta": "This service provides a infrastructure as a-service for running analysis on sensitive data.\nThe ePouta Virtual Private Cloud service allows customers to provision virtual machines and\nstorage resources directly to their own internal networks. It provides an easy to use admin web interface and\na programmable API for managing virtual machines, networks and storage. CSC ePouta meets elevated information\nsecurity level regulations and is targeted for sensitive data processing\n",
    "Chipster": "Chipster is a user-friendly analysis software for high-throughput data.\nIt contains over 300 analysis tools for next generation sequencing (NGS),\nmicroarray, proteomics and sequence data.\nUsers can save and share automatic analysis workflows, and visualize data interactively using\na built-in genome browser and many other visualizations.\n\n### Features:\n\n\n  - Federated authentication through the EGI Applications on Demand service.\n\n  - Web based access.\n\n  - Execution of analysis tools from the Chipster toolbox.\n",
    "CloudFerro Data Collections Catalog": "The Catalogue is be based on CKAN open source software which is widely used for open data publications like\ne.g. European Data Portal, data.org.uk or danepubliczne.gov.pl. CKAN provides user friendly web interface\nfor all activities associated with data publication and subscription.\nIt is capable of advanced data management.\nAll datasets are organized and described with metadata, which allows it to be easily discoverable,\nwith the use of search phrases and customizable filters (e.g.: tags, categories, data formats).\nIt is possible to publish one dataset in different data formats, not only as downloadable files but also\nas links to web service, web API or links to external WWW resources. Datasets can be stored in CKAN,\nalong with version history and dataset statistics, which allows to monitor the interest in datasets.\nCKAN also provides functionalities for collaboration, community participation and providing feedback,\nsuch as comments, ratings and sharing.\nCKAN is highly customizable in both terms of Look&Feel and functionalities.\nCKAN provides very rich RESTful JSON API, which allows other applications to discover and access the datasets.\nIt can be integrated easily with Semantic Web technologies such as RDF data model and SPARQL.\n",
    "CloudFerro Infrastructure": "CREODIAS processing covers full set of virtual resources available in the solution:\nVM \u2013 Virtual Machines (or virtual computing servers) with several operating systems available\n(both free like CentOS, Ubuntu, Debian, Scientific Linux,\nand commercial like RedHat, SUSE, Microsoft Windows Server),\nvirtual storage volumes that can be easily mounted to the VMs together with object storage solution,\nvirtual networks, virtual appliances like firewalls (FWaaS) and VPN concentrators (VPNaaS),\nphysical servers (baremetal) that can be integrated to the virtual world,\nSingle Server VMs \u2013 full physical server with a single VM and very fast passthrough NVMe storage \u2013\na combination of advantages of a dedicated server and a cloud VM\n(high capacity, storage speed, no noisy neighbor problem).\n",
    "Cloudferro Data related Services - EO Finder": "The Finder tool allows finding data products stored in the repository, obtained or processed at\nselected times with selected cloud coverage levels and with other selection criteria.\n",
    "Cloudferro Data related Services - EO browser": "CreoDias EO browser allows browsing wide archive of Earth Observation products, created  by\nESA\u2019s [Sentinel 1][1], [Sentinel 2][2], [Sentinel 3][3], ESA\u2019s archives of [Landsat 5][4], [Landsat 7][5],\n[Landsat 8] [6] and [Envisat][7].\n\nIt provides ability to visualize and download chosen products in .png and .jpg formats.\n\n[1]: https://sentinel.esa.int/web/sentinel/missions/sentinel-1\n[2]: https://sentinel.esa.int/web/sentinel/missions/sentinel-2\n[3]: https://sentinel.esa.int/web/sentinel/missions/sentinel-3\n[4]: https://landsat.gsfc.nasa.gov/landsat-5/\n[5]: https://landsat.gsfc.nasa.gov/landsat-7/\n[6]: https://landsat.gsfc.nasa.gov/landsat-8/landsat-8-overview/\n[7]: https://earth.esa.int/web/guest/missions/esa-operational-eo-missions/envisat\n",
    "DARIAH Science Gateway": "The DARIAH Science Gateway provides various web-based applications and services for the Digital Humanities researchers, institutes and communities.\n\n### Features:\n\nThe DARIAH Science Gateway offers easy access to the following applications:\n\n  - Simple Semantic Search Engine (SSE): Allows users to search in the\n  e-Infrastructure Knowledge Base (Open Access Document Repositories and Data Repositories).\n  - Parallel Semantic Search Engine (PSSE): A parallelised version of SSE enabling simultaneously\n  search across the e-Infrastructure Knowledge Base, Europeana, Cultura Italia, Isidore, OpenAgris,\n  PubMed and DBpedia platforms.\n  - DBO@Cloud: A Cloud-based repository presenting 100+ years old collection of Bavarian dialects.\n  - Cloud Access service: Single-job applications and parameter-sweep applications can be run on\n  the DARIAH VO clouds without porting efforts.\n  - Workflow Development service: Complex workflow applications can be developed and run\n  on all the resources of the DARIAH VO.\n  - File transfer service: Enables transferring data from, to and between storage services providing HTTP,\n  HTTPS, SFTP, GSIFTP, SRM, iRODS and S3 protocols.\n",
    "DisVis": "DisVis is a software designed to visualize and quantify the accessible interaction space\ndefined by distance restraints between biomolecules.\n",
    "Dynamic On Demand Analysis Service (DODAS Portal)": "DODAS acts as cloud enabler designed for scientists seeking to easily exploit distributed\nand heterogeneous clouds to process data. Aiming to reduce the learning curve as well as\nthe operational cost of managing community specific services running on distributed cloud,\nDODAS completely automates the process of provisioning, creating, managing and accessing\na pool of heterogeneous computing and storage resources.\n\n### DODAS provides:\n\n  - A comprehensive approach to opportunistic computing, with the possibility of\n  orchestrate multiple centers (e.g. campus facilities, public or private clouds,\n  to gather all available computing and storage resources).\n  - A simple solution for elastic computing site extensions, e.g. extension\n  of allocated resources in order to absorb peaks of usage.\n  - An easy and controlled procedure to dynamically instantiate a spot \u2018Data Analysis Facility\u2019,\n  for example a mission specific site. This is meant as the generation of an ephemeral WLCG-Tier\n  as a Service to share computing and data resources with collaborators.\n  - The support to create HTCondor batch systems and BigData Platform\n  on demand over multi-backend IaaS cloud resources.\n\n\n### How to access the service\n\nTo access the DODAS service, users are first required to [register online][1].\n\n\n### See the online manual:\n\nhttps://dodas.gitbook.io/dynamic-on-demand-analysis-service\n\n\n### Service provided by\n\nThe service is provided by the Italian National Institute of Nuclear Physics (INFN).\n\nThe DODAS service builds on EOSC-hub services developed during the INDIGO-DataCloud project\n(Identity Access Management - IAM, Token Translation Service - TTS, PaaS Orchestration, TOSCA Templates).\n\n[1]: https://dodas-iam.cloud.cnaf.infn.it/register\n",
    "EGI Archive storage": "Archive Storage allows you to store large amounts of data in a secure environment freeing up\nyour usual file storage resources. Access to the archive can be given at an individual,\nsmall group or large collaboration level.\n\nAll the files in Archive Storage are easily located and retrieved to and from different types of platforms.\n\nThe data on Archive Storage can be replicated across several storage sites,\nthanks to the adoption of interoperable open standards.\nMore copies of your archives mean fewer opportunities for disaster.\n\n\n### To access the service you need to:\n\n   1. Request access selecting one of the service options below.\n   2. Set the relevant parameters and add the service to the cart.\n   3. Go to the cart and submit your order.\n   4. You will receive an email summarising your order.\n   5. You will be contacted by the EGI support team.\n",
    "EGI Check-in": "Check-in is a proxy service that operates as a central hub to connect federated Identity Providers (IdPs)\nwith service providers. Check-in allows users to select their preferred IdP so that they can access and use\nservices in a uniform and easy way. For the user the feature is transparent:\nas soon as their IdP is integrated with the proxy, they are redirected by the service to their own IdP.\nOnce integrated the IdP with the proxy, all the services using the IdP proxy will be available.\nThe service providers will get all the AuthN/AuthZ information needed from the IdP Proxy\n(in form of attributes), without the need to deal with individual IdPs.\n\nOther components that can be attached to the IdP Proxy are credential translation services\nand attribute authorities.\n\n### Main characteristics:\n\n  - Enables multiple federated authentication sources using\n  different technologies\n  - Increased productivity and security\n  - Federated in eduGAIN as a service provider, publishingREFEDS RnSandSirtficompliance\n  - User registration portal to allow accounts-linkingo\n  - Combines user attributes originating from various authoritative sources\n  (IdPs and attribute provider services) and delivers them to the connected service providers\n  in a transparent way.\n\n### Features:\n\n- Enables federated access to services:\n    *Support for IdPs: SAML2.0, OIDC\n    * Support for SPs: SAML2.0, OIDC\n- Connection with the CILogon TTS\n- Enables multiple federated authentication sources using different technologies\n- Direct integration with the communities AAI services\n- User registration portal to allow accounts-linking\uf0b7Provisioning to SPs of an EGI User UID\n\n\nBrochure: https://www.egi.eu/wp-content/uploads/2017/09/Check-in.pdf\n",
    "EGI Cloud compute": "With Cloud Compute you can deploy and scale virtual machines\non\u00addemand. Cloud Compute offers guaranteed computational resources in\na secure and isolated environment with standard API\naccess, without the overhead of managing physical servers.\nCloud Compute offers the possibility to select pre\u00adconfigured virtual\nappliances (e.g. CPU, memory, disk, operating system or software)\nfrom a catalogue replicated across all EGI cloud providers.\n\n### To access the service you need to:\n\n 1. Request access selecting one of the service options below.\n 2. Set the relevant parameters and add the service to the cart.\n 3. Go to the cart and submit your order.\n 4. You will receive an email summarising your order.\n 5. You will be contacted by the EGI support team.\n\n### Featured use cases:\n\n\n[How to predict social media trends?][1] how Cloud Compute helps to\ntest new ways to detect trends on social networks\n\n[The genetics of Salmonella infections:][2] how Cloud Compute\nhelped scientists to understand what happens during when a human cell meets Salmonella\n\n\n[1]: https://www.egi.eu/use-cases/research-stories/how-to-predict-social-media-trends/\n\n\n[2]: https://www.egi.eu/use-cases/research-stories/the-genetics-of-salmonella-infections/\n",
    "EGI Cloud container compute BETA": "With Cloud Container Compute you can deploy and scale Docker containers on-demand. It offers guaranteed computational resources in a secure and isolated environment with standard API access, without the overhead of managing the operating system.\n\nThe result is improved performance, ideal for development.\n\n### To access the service you need to:\n\n  1. Request access selecting one of the service options below.\n  2. Set the relevant parameters and add the service to the cart.\n  3. Go to the cart and submit your order.\n  4. You will receive an email summarising your order.\n  5. You will be contacted by the EGI support team.\n",
    "EGI High-Throughput compute": "With High-Throughput Compute you can run computational jobs at scale on the EGI infrastructure. It allows you to analyse large datasets and execute thousands of parallel computing tasks.\n\nEGI offers more than 650,000 cores of installed capacity, supporting about 1.6 million computing jobs per day.\n\n### To access the service you need to:\n\n  1. Request access selecting one of the service options below.\n  2. Set the relevant parameters and add the service to the cart.\n  3. Go to the cart and submit your order.\n  4. You will receive an email summarising your order.\n  5. You will be contacted by the EGI support team.\n\n### Featured use cases:\n\n[What happens when molecules collide?][1] How High-Throughput Compute helps researchers to simulate chemical reactions. <br>\n[Small settlements coalesce into larger cities][2]: how the OpenMOLE platform and High-Throughput Compute helped to validate a long-held theory in geography\n\n[1]: https://www.egi.eu/use-cases/research-stories/what-happens-when-molecules-collide/\n\n[2]: https://www.egi.eu/use-cases/research-stories/cities/\n",
    "EGI Notebooks": "The service provides a browser-based tool for interactive analysis of data using EGI storage\nand compute infrastructures based on the JupyterHub technology. The notebooks can combine text,\nmathematics, computations and their rich media output using Jupyter technology, and can scale\nto multiple servers and multiple users (hub) with the EGI cloud service.\n\n### The service is proposed in two options:\n\n  1. For individual users EGI hosts and offers a JupyterHub within the Applications On Demand Service.\n  Users (after lightweight approval) can login, write and play notebooks\n  using storage and compute capacity from the access.egi.eu VO.\n  2. For user communities EGI offers consultancy and technology\n  to setup a community-specific JupyterHub on top of community VO\n  (together with EGI-enbled compute and storage resources), and with community-specific storage/data.\n",
    "EGI Online Storage": "Store, share and access your files and their metadata on a global scale.\n\nOnline Storage allows you to store data in a reliable and high-\u00adquality environment and share it\nacross distributed teams. Your data can be accessed through different standard protocols and can be\nreplicated across different providers to increase fault\u00ad-tolerance.\n\nOnline Storage gives you complete control over the data you share and with whom.\n\n\n### To access the service you need to:\n\n  1. Request access selecting one of the service options below.\n  2. Set the relevant parameters and add the service to the cart.\n  3. Go to the cart and submit your order.\n  4. You will receive an email summarising your order.\n  5. You will be contacted by the EGI support team.\n",
    "ENES Climate Analytics Service": "Users can define parallel processing workflows, executed remotely without needing\nto download data or provide own computing resources as these are provided by ECAS.\nMoreover, users can explore workflows others have created and shared, and apply these to their own data.\nECAS enables users to write a workflow once and apply it to diverse data without having to customize it again.\n\n### To access the service you need to:\n\nECAS is open for use by users interested in working on Earth Sciences data.\nAvailable data sources may be different between CMCC and DKRZ.\n\nTo use ECAS and to learn more about the different datasets available,\nplease follow the instructions for registration and access at the two sites:\n\n  - [CMCC][1]\n  - [DKRZ][2]\n\n\n### See the online manual:\n\n  - [Ophidia][3]\n  - [More about Ophidia][4]\n  - [ENES][5]\n  - [IS-ENES][6]\n  - [ESGF][7]\n\n[1]: https://ophidialab.cmcc.it/\n[2]: https://ecaslab.dkrz.de/\n[3]: http://ophidia.cmcc.it/\n[4]: http://ophidia.cmcc.it/documentation/\n[5]: https://verc.enes.org/\n[6]: https://is.enes.org/\n[7]: http://esgf.llnl.gov/\n",
    "EODC Data Catalogue Service": "The EODC Data Catalogue service allows querying the Copernicus Sentinel satellite data hosted at EODC.\nThe service is available through a  simple Web GUI, eomEX+, as well as an API. The back-end of eomEX+\nis the EODC pycsw server, an implementation of an OGC CSW server. As a consequence,\nthe eomEX+ API is accompanied by an expert level  API provided by the EODC CSW server, located at [link][1].\n\nFurther details can be found [here][2].\n\n\n[1]: https://csw.eodc.eu\n[2]: https://eomex.eodc.eu/manual\n",
    "EODC JupyterHub for global Copernicus data": "EODC JupyterHub provides access to the global EODC Copernicus Data Archive.\nEliminate the barrier to get access to and to start to develop algorithms in view of remote sensing data.\nFull access to EODC Copernicus satellite data archive.\nNo need to setup a VM to access data archive.Simple python dev. environment.\n",
    "Elastic Cloud Compute Cluster (EC3)": "The Elastic Cloud Computing Cluster (EC3) is a platform that allows creating elastic virtual clusters\non top of Infrastructure as a Service (IaaS) providers, either public (such as Amazon Web Services,\nGoogle Cloud or Microsoft Azure) or on-premises (such as OpenNebula and OpenStack).\nThrough a 'job wizard' interface, the user can configure the virtual cluster with a predefined set\nof applications that will be deployed in the clouds underpinning the EGI Applications On Demand infrastructure.\nThe installation and the configuration of the cluster are performed by means of the execution\nof Ansible receipts. The cluster configured by EC3 is private: as soon as it is configured\nthe user will have root access to the environment, and can setup and configure the cluster\ninstalling additional libraries and software to their needs.\n\n### Features:\n\n  - Federated authentication through the EGI Applications on Demand service.\n  - Web based access.\n  - Interoperability with most widely used IaaS cloud technologies\n  - Wizard interface to streamline the configuration and the deployment of the virtual cluster on top of Infrastructure as a Service (IaaS) providers.\n  - Several Ansible receipts are available to deploy applications and tools in the cluster nodes.\n  - Nodes of the clusters will be self-managed by CLUES. Working nodes will be undeployed when they are idle.\n  - Use of \u2018per-user subproxies\u2019 from EGI to access X.509-protected resources on the users\u2019 behalf.\n",
    "FANTEN": "FANTEN is a user-friendly web tool for the\ndetermination of anisotropy tensors. It is freely available through the WeNMR gateway.\n\nThe portal was developed with the help of the WestLife and INDIGO-DataCloud projects\nand supported by the MoBrain Competence Centre, under the EGI-Engage project.\n",
    "FitSM": "FitSM is a lightweight standards family aimed at facilitating service management in IT service provision,\nincluding federated scenarios. FitSM training aims at providing those involved in operating\nfederated infrastructures with the professional skills they need in order\nto effectively manage their services.\n\nFitSM professional training is certified by T\u00dcV S\u00dcD, a global leader in standardisation and certification.\nThe qualification programme offers three training levels: Foundation, Advanced and Expert.\n\n\n### To request a training you need to:\n\n1. Choose the training courses that best fit with your needs below.\n2. Add the courses to the cart.\n3. Go to the cart and submit your order.\n4. You will receive an email summarising your order.\n5. You will be contacted by the EGI support team.\"\n",
    "GEO DAB": "\nGEO Discovery and Access Broker (GEO DAB) is a key component of the GEOSS Platform,\ntransparently connecting GEOSS User\u2019s requests to the resources shared by the GEOSS Providers.\n\nGEO DAB scope is to simplify cross and multi-disciplinary discovery, access, and use (or reuse)\nof disparate data and information.\n\nGEO DAB is a brokering framework that interconnects hundreds of heterogeneous and autonomous\nsupply systems (the enterprise systems constituting the GEO metasystem) by providing mediation,\nharmonization, transformation, and QoS capabilities.\n\nGEO DAB can be accessed using several web service interfaces, available at [link][1].\n\n[1]: http://eosc.geodab.eu/gi-cat-StP/\n",
    "GEOSS Web Portal": "The GEOSS (Global Earth Observation System of Systems) Web Portal is the main entry point\nfor discovering and accessing GEOSS data. GEOSS Platform interconnects more than 170 data systems globally,\nproviding discoverability of more than 400M datasets.\nThis version of the GEOSS Web Portal is connected also to the ECOPotential Virtual Laboratory,\nallowing users to execute available models utilizing GEOSS data as inputs.\n",
    "GEP - EO Services for Earthquake Response and Landslides Analysis": "This is a Thematic Application of the Geohazards Thematic Exploitation Platform providing access to a set\nof on-demand terrain motion services supporting interferogram generation, co-seismic displacement mapping,\nlandslide rapid mapping and landslide displacement field monitoring with Sentinel-1 and Sentinel-2 data.\n",
    "GEP - High-Resolution Change Monitoring for the Alpine Region": "This service provides an interferometric product at 50m resolution and 25m pixel spacing systematically\nfor every 6-day Sentinel-1 SLC pair over the Alpine Region.\nIt allows rapid response to earthquakes occurring within the processing mask by automatic generation\nof co-seismic interferograms that are published in a dedicated GeoBrowser\nand made available for visualization and download.\n",
    "HADDOCK": "HADDOCK is a web portal that offers computational tools for structural biologists to model the structure\nof complexes of proteins and other biomolecules via a user-friendly interface. The portal offers a number\nof interfaces, depending on the amount of information and restraints that researchers wish\nto place on their models.\nHADDOCK is prepared to deal with several classes of problems,\nincluding protein-protein, protein-nucleic acids and protein-ligand complexes.\n",
    "Language Resource Switchboard": "A web application that suggests language analysis tools for specific\ndata sets, enabling the following tasks:\n\n  **Sentence level analysis**:\n\n  - Constituency Parsing\n  - Dependency Parsing\n  - Shallow Parsing\n\n  **Word level analysis**:\n\n  - Lemmatization\n  - Morphological Analysis\n  - Named Entity Recognition\n  - Part-Of-Speech Tagging\n\n  **Semantic analysis**:\n\n  - Coreference Resolution\n  - Sentiment Analysis\n  - Text Summarization\n\n  **Digital Humanities analysis**:\n\n  - Distant Reading\n  - Named Entity Linking\n  - Stylometry\n  - Topic modelling\n\nThe [Language Resource Switchboard][1] will automatically provide a list\nof available tools, based on the language and format of the input.\nThe Switchboard can also be invoked from the [Virtual Language Observatory][2]\nand B2DROP (see Suggested compatible services below).\n\n[1]: https://switchboard.clarin.eu\n[2]: https://vlo.clarin.eu\n",
    "LifeWatch ERIC Plants Identification App": "This web service connects to a deep neural network which has been trained with thousands\nof plant images from Europe. It can classify different types of plants, including flowers.\nThe input to be sent to the web service is an image URL or a local image.\nThe response is a JSON with the potential classification (the name of the potential specie),\na percentage, link to google images and link to wikipedia.sets.\n\n### How to access the services:\n\nThe service is freely available online.\n\nThe service is provided as a REST API and it uses JSON over HTTP as communication channel. Example:\n\n```\n    curl --data 'mode=url&url_list=https://public-media.smithsonianmag.com/filer/89/47/8947cd5c-ac01-4c0e-891a-505517cc0663/istock-540753808.jpg&url_list=https://cdn.pixabay.com/photo/2014/04/10/11/24/red-rose-320868_960_720.jpg' http://deep.ifca.es/plants/api\n```\n\n### See the online manual:\n\nhttps://github.com/IgnacioHeredia/plant_classification/blob/master/webpage/README.md#using-the-api\n\n\n### Service provided by\n\nThe Service is provided by LifeWatch ERIC.\n",
    "MEA Platform (Data access and exploitation service)": "MEA platform implements the concept of Digital Earth making global environmental geospatial data Findable,\nAccessible, Interoperable and Reusable (FAIR). MEA platform provides an effective subsetting functionality\nthat accesses the data only when requested and serves to the client\nonly the data amount that is really needed.\nMEA platform exposes OGC-standardised discovery (openSearch) and access (WCS 2.0) interfaces.\n",
    "New Particle Formation Event Analysis": "The VRE supports new particle formation event analysis on interoperable e-Infrastructures.\nIt provides access to Jupyter notebooks to classify events and process information about them.\nIt integrates the SMEAR Research Infrastructure (provider of primary data) and uses EGI\nand D4Science services to support primary data interpretation and the cataloging of data derived in analysis.\nAccess to the VRE requires a D4Science account.\n",
    "OPENCoastS Portal": "OPENCoastS builds on-demand circulation forecast systems for user-selected sections\nof the North Atlantic coast and maintains them running operationally for the timeframe defined by the user.\nThis daily service generates forecasts of water levels and 2D velocities over the spatial region\nof interest for periods of 48 hours, based on numerical simulations of the relevant physical processes.\nForcing conditions at the boundaries and over the domain are defined by the user\nfrom global forecast databases. Automatic comparison with real-time in-situ sensor data can be provided\nfor a number of user specified locations.\n\nIt takes advantage of LNEC\u2019s team long-term work on coastal modelling as model developers,\nintegrated in several open source modelling communities (SCHISM, ELCIRC, SELFE, ADCIRC),\nand in its advanced competences  in developing forecast frameworks and operating forecasts deployments.\n\n### Users and application potential\n\nOPENCoastS can contribute directly to the development of new research methodologies\nand workflows regarding water quality, biological, biochemical and coastal erosion studies.\n\nSMEs will benefit from these operational systems to feed their own higher-level service portfolios\nto respond to other societal needs, without the need\nto invest time and resources to deploy forecast systems from scratch.\n\nPort and coastal authorities \u2013Through the use of this platform coastal managers have all the information\nrequired to fulfill their responsibilities (examples of uses include facilitating navigation,\nreducing port operation costs, reducing emergency planning and response of coastal hazards,\nand better exploring recreational uses of the coast).\n\n\n### How to request a service\n\nTo request use of the OPENCoastS, please fill in thee request form and register at\nhttps://opencoasts.ncg.ingrid.pt/. After analysis and validation of the request,\nyou will be allowed to log in and start building your forecasts.\n\n\nService provided by\n\nOPENCoastS is provided by the Portuguese National Civil Engineering Laboratory,\nand was jointly developed by LNEC and LIP.\n\nCurrently, the service is deployed at a single computing site (NCG-INGRID-PT,\npart of [INCD][1] and the [EGI Federation][2]).\n\nThrough EOSC-hub, OPENCoastS will be expanded to include a more diverse set of geographical data,\nand improved with integration of new features from the EGI, EUDAT and INDIGO-DataCloud service catalogues.\n\n[1]: http://www.incd.pt/\n[2]: https://www.egi.eu/federation/\n",
    "PAN gitlab": "Repository service for EOSC PAN notebooks and cloud functions for EOSC PAN FaaS. Gitlab runners\nfor continuous integration in the DESY Compute Cloud,\nbuilding and publishing docker containers in the project registry.\n",
    "PROMINENCE": "PROMINENCE is a platform which allows users to exploit idle cloud resources for running scientific workloads\nwith a simple batch system style interface. Key features include:\n\n  - Jobs can be submitted from anywhere using any OS and any language.\n  - All jobs are run in containers to ensure they will can run reliably anywhere and are reproducible.\n  - Multi-node OpenMPI jobs can be run in addition to HTC jobs.\n  - On-premises resources can be utilised with the ability to burst onto external clouds\n    at times of peak demand.\n  - Goes beyond bursting onto a single external cloud with hierarchical cloud bursting.\n    For example, burst onto national research clouds, to EGI FedCloud and finally to public clouds.\n  - All infrastructure provisioning is handled completely automatically and is totally transparent to the user.\n  - Clouds are selected automatically based on job requirements and preferences,\n    and any failures are handled automatically.\n  - Output data can be accessed from cloud-based object storage.\n",
    "PaN data": "Data backend storage service for EOSC PAN notebooks and cloud functions for EOSC PAN FaaS.\nStreams for storage events via kafka and Server Sent Events.\nDelegation of read/write access with Macaroons.\n",
    "PaN faas": "Compute backend service for EOSC PAN notebooks and EOSC PAN data.\nContinuous integration and deployments of docker containers as cloud functions on the DESY Compute Cloud.\n",
    "PaN notebook": "Spawn Jupyter Servers in the DESY Compute Cloud and run notebooks which can make use\nof the EOSC PaN FaaS Service and connect to EOSC PaN Data Service.\n",
    "PowerFit": "PowerFit is a software designed to fit atomic structures into cryo-EM density maps,\nusing an exhaustive 6-dimensional cross-correlation search.\n",
    "Rasdaman EO Datacube": "Rasdaman is a datacube engine providing analysis-ready EO data by abstracting\nmillions of satellite images into few spatio-temporal cubes.\nVisualize via WMS, extract via WCS or perform server-side analytics via WCPS\non any subset of Sentinel or Landsat data in real time, in your favorite client.\n",
    "Sentinel Hub": "Sentinel Hub is a multi- spectral and multi-temporal big data satellite imagery service,\ncapable of fully automated archiving, real-time processing and distribution\nof remote sensing data and related EO products.\nUsers can use OGC compliant and proprietary APIs to retrieve satellite data over their AOI\nand specific time range from full archives in a matter of seconds.\nSentinel Hub received Copernicus Masters Award 2016.\n",
    "SpotOn": "SpotOn is a robust algorithm developed to identify and classify the interfacial residues\nas Hot-Spots (HS) and Null-Spots (NS) with a final accuracy of 0.95\nand a sensitivity of 0.95 on an independent test set.\n",
    "TDS": "This service provides researchers with a desktop with secure storage and software\nto run your collection and analysis of sensitive data. The system is built on the idea\nthat having a robust firewall around a system that provides a full separation of projects, is the best policy.\nA two-step authentication is needed to gain access to the system. Inside the system,\nevery project has its own VLAN and its own virtual file system.\nThis means that projects cannot find any information about any other project on the system.\n",
    "Training infrastructure": "The Training Infrastructure is a cloud\u00adbased computing and storage resources for training events.\nIt is useful to organise onsite tutorials or workshops and online training courses or as a platform\nfor self\u00adpaced learning.\n\nTrainers can deploy custom virtual machine images on the Training Infrastructure\nas the training environment for the students. The virtual machines can be customised according\nto specific needs and the community can benefit from the easy deployment and easy reuse\nof course materials.\n\nThe Training Infrastructure uses the same high\u00adquality computing and storage environment\nthat EGI provides to researchers.\n\n### To request a training you need to:\n\n  1. Choose the training courses that best fit with your needs below.\n  2. Add the courses to the cart.\n  3. Go to the cart and submit your order.\n  4. You will receive an email summarising your order.\n  5. You will be contacted by the EGI support team.\n",
    "Virtual Collection Registry": "A service that allows researchers to create their own citable digital bookmarks.\n\n\nA virtual collection is a coherent set of links to digital objects (e.g. annotated text, video)\nthat can be easily created, accessed and cited. The links can originate from different archives,\nhence the term virtual.\n\n\nCLARIN provides a [registry][1] where scholars can create and publish their virtual collections.\nIt provides [persistent identifiers and federated login][2].\n\n\nThe collection metadata is openly available and accessible via the [Virtual Language Observatory][3].\nThe referenced digital objects can also be processed with the [Language Resource Switchboard][4].\n\n[1]: https://www.clarin.eu/vcr\n[2]: https://www.clarin.eu/content/federated-identity\n[3]: https://vlo.clarin.eu\n[4]: https://switchboard.clarin.eu\n",
    "Virtual Language Observatory": "A facet browser for fast navigation and searching in large amounts of metadata.\nThis portal enables the discovery of language data and tools, provided by over 40 CLARIN centres,\nother language resource providers and Europeana.\n\n\nThe [VLO][1] also provides access to the [Virtual Collection Registry][2] metadata and can be used\nas a starting point to process language data with the [Language Resource Switchboard][3].\n\n[1]: https://vlo.clarin.eu\n[2]: https://www.clarin.eu/content/virtual-collections\n[3]: https://switchboard.clarin.eu/\n",
    "WS-PGRADE": "The WS-PGRADE Portal (Web Services Parallel Grid Runtime and Developer Environment Portal)\nis the Liferay-based web portal (WS-PGRADE web application) of gUSE high level middleware system.\nThis WS-PGRADE deployment is operated within the EGI \u2018Applications on Demand\u2019 service and provides\nan easy to use 'Job Wizard' environment for users. Through the Job Wizard one can define with\na few clicks computational jobs that WS-PGRADE will execute on Infrastructure as a Service\nclouds pre-configured by EGI. WS-PGRADE takes care of all aspects of job management in the cloud,\nincluding instantiation of Virtual Machine images and retrieval of outputs. Jobs can be single processor\napplications or 'parameter study' type applications where each instance\nof the job takes different input parameters.\n\n### Features:\n\n  - Federated authentication through the EGI Applications on Demand service.\n  - Graphical interfaces for job definition, job execution, inspection of results.\n  - Web based access.\n  - Interoperability with most widely used IaaS cloud technologies\n  - Job wizard interface to streamline analytical steps.\n  - Use of \u2018per-user subproxies\u2019 from EGI to access X.509-protected resources on the users\u2019 behalf.\n"
}